{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T10:52:08.044453Z",
     "start_time": "2024-11-03T10:52:08.039069Z"
    }
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_url=\"https://www.lag-sb-rlp.de\"\n",
    "category_csv = \"../storage/category_urls.csv\"\n",
    "dataset_csv = \"../storage/dataset.csv\"\n",
    "dataset_path = \"../storage/dataset\"\n",
    "invalid_chars = '<>:\"/\\\\|?*' # forbidden chars for linux file-names"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T10:52:08.320825Z",
     "start_time": "2024-11-03T10:52:08.049087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Fetch the url for each category from Leichte Sprache Bildergalerie\"\"\"\n",
    "def get_categories():\n",
    "    response = requests.get(base_url + \"/projekte/bildergalerie-leichte-sprache\")\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    data = []\n",
    "    category_links = {}\n",
    "    categories_detail_div = soup.find(\"div\", id=\"phocagallery-categories-detail\")\n",
    "    \n",
    "    if categories_detail_div:\n",
    "        for pg_field_div in categories_detail_div.find_all(\"div\", class_=\"pg-legend\"):\n",
    "            a_tags = pg_field_div.find_all(\"a\", href=True)        \n",
    "            for a_tag in a_tags:\n",
    "                category = a_tag.get_text(strip=True).split(\"<\")[0]\n",
    "                link = a_tag[\"href\"]\n",
    "                if link not in category_links:\n",
    "                    category_links[link] = category\n",
    "    \n",
    "    for link, category in category_links.items():\n",
    "        data.append({\"url\": base_url + link, \"category\": category})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(category_csv, index=False)\n",
    "    \n",
    "get_categories()"
   ],
   "id": "4bf487515580cce7",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T10:52:13.798854Z",
     "start_time": "2024-11-03T10:52:08.324028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_category_links(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return list(zip(df[\"url\"], df[\"category\"]))\n",
    "\n",
    "def scrape_elements_in_category(category_link, category):\n",
    "    elements = []\n",
    "    page = 0\n",
    "    while True:\n",
    "        page_link = f\"{category_link}?start={page*50}\" if page > 0 else category_link\n",
    "        response = requests.get(page_link)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        container = soup.find(\"div\", id=\"pg-msnr-container\")\n",
    "        if not container:\n",
    "            break\n",
    "        \n",
    "        items = container.find_all(\"div\", class_=\"pg-cv-box item pg-grid-sizer\")\n",
    "        if not items:\n",
    "            break\n",
    "        \n",
    "        for item in items:\n",
    "            img_div = item.find(\"div\", class_=\"pg-cv-box-img pg-box1\")\n",
    "            title_div = item.find(\"div\", class_=\"pg-box-img-bottom\").find(\"div\", class_=\"pg-cv-name\")\n",
    "            \n",
    "            if not img_div or not title_div:\n",
    "                continue\n",
    "            \n",
    "            img_tag = img_div.find(\"img\")\n",
    "            if img_tag and \"alt\" in img_tag.attrs and img_tag[\"alt\"] == \"Zurück\":\n",
    "                continue\n",
    "            \n",
    "            link_tag = img_div.find(\"a\")\n",
    "            title = title_div.text.strip()\n",
    "            link = link_tag[\"href\"] if link_tag else None\n",
    "            \n",
    "            elements.append({\"category\": category,\"title\": title, \"url\": base_url + link})\n",
    "        \n",
    "        if len(items) < 50:\n",
    "            break\n",
    "        \n",
    "        page += 1\n",
    "    \n",
    "    return elements\n",
    "\n",
    "\"\"\"Get each sample from each category with title and url.\"\"\"\n",
    "def get_image_links():\n",
    "    categories = scrape_category_links(category_csv)\n",
    "    all_elements = []\n",
    "    \n",
    "    for link, category in categories:\n",
    "        elements = scrape_elements_in_category(link, category)\n",
    "        all_elements.extend(elements)\n",
    "    \n",
    "    df = pd.DataFrame(all_elements)\n",
    "    df.to_csv(dataset_csv, index=False)\n",
    "\n",
    "get_image_links()"
   ],
   "id": "1047b6adfcd6804c",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T10:55:24.293102Z",
     "start_time": "2024-11-03T10:52:13.799860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_title(title):    \n",
    "    for char in invalid_chars:\n",
    "        title = title.replace(char, \"_\")\n",
    "    return title\n",
    "\n",
    "\"\"\"create .png file for each sample image and .txt file for each image description \"\"\"\n",
    "def download_images_and_update_csv():\n",
    "    df = pd.read_csv(dataset_csv)\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.makedirs(dataset_path)\n",
    "    \n",
    "    total_elements = len(df)\n",
    "    progress_bar = tqdm(total=total_elements, desc=\"articles scraped\", unit=\"article\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        raw_title = row[\"title\"]\n",
    "        link = row[\"url\"]        \n",
    "        title = clean_title(raw_title)\n",
    "        \n",
    "        folder_name = os.path.join(dataset_path, title)\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "        \n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        image_box = soup.find(\"div\", id=\"phocaGalleryImageBox\")\n",
    "        if image_box:\n",
    "            img_tag = image_box.find(\"img\")\n",
    "            if img_tag and \"src\" in img_tag.attrs:\n",
    "                image_url = base_url + img_tag[\"src\"]\n",
    "                \n",
    "                img_response = requests.get(image_url)\n",
    "                img_path = os.path.join(folder_name, title + \".png\")\n",
    "                with open(img_path, \"wb\") as img_file:\n",
    "                    img_file.write(img_response.content)\n",
    "        \n",
    "        text_box = soup.find(\"td\", class_=\"pg-dv-desc no-popup\")\n",
    "        if text_box:\n",
    "            p_tag = text_box.find(\"p\")\n",
    "            if p_tag:\n",
    "                text_content = p_tag.get_text(strip=True)\n",
    "                # clean image description and save it in csv\n",
    "                text_path = os.path.join(folder_name, title + \".txt\")\n",
    "                with open(text_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "                    text_file.write(text_content.replace(\"Download\", \"\").replace(\"\\u00A0\", \" \"))\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    print(f\"download completed\")\n",
    "\n",
    "download_images_and_update_csv()"
   ],
   "id": "547efdf57baedaf6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "articles scraped: 100%|██████████| 414/414 [03:10<00:00,  2.17article/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T10:55:24.514094Z",
     "start_time": "2024-11-03T10:55:24.296317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"For further investigation of the dataset, you can add the image resolution and description to dataset.csv \"\"\"\n",
    "def add_description_and_resolution():\n",
    "    df = pd.read_csv(dataset_csv)    \n",
    "    df[\"description\"] = None\n",
    "    df[\"resolution\"] = None\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        titel = clean_title(row[\"title\"])\n",
    "        txt_file_path = None\n",
    "        img_file_path = None\n",
    "        \n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            if titel in dirs:\n",
    "                txt_file_path = os.path.join(root, titel, f\"{titel}.txt\")\n",
    "                img_file_path = os.path.join(root, titel, f\"{titel}.png\")\n",
    "                break\n",
    "        \n",
    "        if txt_file_path and os.path.isfile(txt_file_path):\n",
    "            with open(txt_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                description = file.read().strip()\n",
    "                df.at[i, \"description\"] = description\n",
    "        \n",
    "        if img_file_path and os.path.isfile(img_file_path):\n",
    "            try:\n",
    "                with Image.open(img_file_path) as img:\n",
    "                    resolution = f\"{img.width}x{img.height}\"\n",
    "                    df.at[i, \"resolution\"] = resolution\n",
    "            except Exception as e:\n",
    "                print(f\"could not read image resolution for {img_file_path}: {e}\")\n",
    "    \n",
    "    df.to_csv(dataset_csv, index=False)\n",
    "\n",
    "add_description_and_resolution()"
   ],
   "id": "8f5fe75179cad76",
   "outputs": [],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
